# 一、背景

一般情况下，前端上传文件就是`new FormData`，然后把文件 `append` 进去，然后`post`发送给后端就完事了，但是文件越大，上传的文件也就越长，如果在上传过程中，突然被网管拔了网线，又或者电脑突然中木马了，又或者请求超时，等待过久等等情况，十分影响甲方大哥的体验。

所以这时候就要用到大文件上传了，确保能让用户在上传的时候想停就停（**暂停功能**），就算断网了也能继续接着上传（**断点上传**），如果是之前上传过这个文件了（服务器还存着），就不需要做二次上传了（**秒传**）

# 二、`Web Worker`

关于 `Web Worker` 如果想要了解更多可以先参考阮一峰大佬的 [Web Worker 使用教程](https://link.juejin.cn?target=https%3A%2F%2Fwww.ruanyifeng.com%2Fblog%2F2018%2F07%2Fweb-worker.html)，以及一些具体用例 [一文彻底了解Web Worker](https://juejin.cn/post/7137728629986820126?searchId=20240627114039E0FE301AD011603DD657)。

我们都知道，如果让浏览器中`JS`有大量计算时，会造成 `UI` 阻塞，出现界面卡顿、掉帧等情况，严重时还会出现页面卡死等情况（其实很容易触发，例如让你计算十万条数据）。

这时候该怎么办呢？该 **`Web Worker`** 登场了，在`HTML5`的新规范中，实现了 `Web Worker` 来引入 `js` 的 “多线程” 技术, 可以让我们在页面主运行的 `js` 线程中，加载运行另外单独的一个或者多个 js 线程。

**总结就是： `Web Worker`专门处理复杂计算的，从此让前端拥有后端的计算能力**

所以 **`Web Worker`** 对大文件上传来说有什么用呢？假如我们把 `10G` 的文件要进行切割成每块`1MB`的小文件，那岂不是会生成10万个切片，所以这时候就需要用到 **`Web Worker`** 了。

具体用法在代码中我会解释，又或者可以参考上面两篇文章（注意 `webpack4` 跟 `webpack5` 使用方法不一样，具体要看官方文档使用说明，下面我只针对 `vue-cli5` 跟 `vite` 去使用）

# 三、前端部分

在实现代码之前，先把流程捋一下：首先前端拿到超大文件，需要把文件进行切割分成固定大小的切片，再通过`http`请求把所有的切片传给后端，后端拿到切片后，处理每一个切片并返回是否处理成功给前端，等把所有的切片都上传完后，后端再把所有的切片合并成一个完整的文件，代表大文件上传完成！

好，那`http`请求就得用到 `axios` ，当然你也可以使用原生 `XMLHttpRequest` 去做请求，以下就直接使用 `axios`去实现了。

考虑到要把文件切片，那怎么知道每一个文件的唯一标识呢？我们可以用到 `speak-md5` 去计算文件的`hash值`。这样如果就算![js1](D:\张旭资料\knowledge-notes\前端知识\js\images\js1.png)文件同名那它的唯一标识也会不同，又或者文件内容更改后得到的`hash`值也会不同。

## 一个上传组件，需要具备的功能：

1. 需要校验文件格式
2. 可以上传任何文件，包括超大的视频文件（切片）
3. 上传期间断网后，再次联网可以继续上传（断点续传）
4. 要有进度条提示
5. 已经上传过同一个文件后，直接上传完成（秒传）

## 前后端分工：

#### 前端：

1. 文件格式校验
2. 文件切片、`md5`计算
3. 发起检查请求，把当前文件的`hash`发送给服务端，检查是否有相同`hash`的文件
4. 上传进度计算
5. 上传完成后通知后端合并切片

#### 后端：

1. 检查接收到的`hash`是否有相同的文件，并通知前端当前`hash`是否有未完成的上传
2. 接收切片
3. 合并所有切片

## 几个问题：

#### 如何切片？

核心是 `Blob` 对象的 `slice` 方法。

![cj1](.\images\cj1.png)

#### 一个文件切片之后怎么知道这些切片是这个文件的？或者说文件被切完片了在服务端怎么保存？（主要是针对多个文件上传的情况，文件一有多个切片、文件二有多个切片，怎么分清楚这些切片隶属于谁）

利用文件的 `hash` 值作为该文件所有切片的文件夹。

![cj2](.\images\cj2.png)

比如文件一的 `hash` 值为 `18bbdc5f4b5d1fc7f62045e16a37dcb6` ，则以它为文件一所有切片的文件夹的名称，之后该文件的所有切片都放置该文件夹下

#### 为什么是 `hash` 值？

先思考一个问题，在向服务器上传文件时，怎么去区分不同的文件呢？如果根据文件名去区分的话可以吗？

答案是**不可以**，因为文件名我们可以是随便修改的，所以不能根据文件名去区分。但是每一份文件的文件内容都不一样，我们可以根据文件的内容去区分，具体怎么做呢？

答案是文件的 `hash` 值。文件 `hash` 值是依据文件内容产生的**唯一值**，且文件内容变化对应的 `hash` 值也会变化。

> 因为我们需要找到文件的唯一标识作为文件夹名称，这样才能区分所上传的不同的文件

#### 一个文件被切成一片一片的，之后怎么完整的显示整个文件的内容？也就是合并时如何按照正确的顺序合并？

这里就要讲到一个切片命名时的技巧了。前端在进行文件的切片之后，对每一个切片的命名可以带上索引值。后续服务端在进行切片合并时，就可以根据索引值将所有切片正d确拼接。

#### 什么是秒传？真的是一秒上传所有吗？

显然不是。秒传的实现其实是判断服务端是否已经又该文件的信息，有，则通知无需上传，这就是所谓的秒传

#### 什么是断点续传？

断点续传其实就是：对于一个大文件而言，它的切片可能有很多个（取决于每个切片的大小和源文件的大小）但这个文件上传一半，已经上传了部分切片了，那么下一次再次选择上传这个文件时，就可以不用上传已上传的切片。这就是断点续传

![cj3](.\images\cj3.png)

# 四、前端详情实现过程

## 文件分片 & `Hash`计算

```js
/**
 * 将目标文件分片 并 计算文件Hash
 * @param {File} targetFile 目标上传文件
 * @param {number} baseChunkSize 上传分块大小，单位Mb
 * @returns {chunkList:ArrayBuffer,fileHash:string}
 */
async function sliceFile(targetFile, baseChunkSize = 1) {
  return new Promise((resolve, reject) => {
    //初始化分片方法，兼容问题
    let blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice;
    //分片大小 baseChunkSize Mb
    let chunkSize = baseChunkSize * 1024 * 1024;
    //分片数
    let targetChunkCount = targetFile && Math.ceil(targetFile.size / chunkSize);
    //当前已执行分片数
    let currentChunkCount = 0;
    //当前以收集的分片
    let chunkList = [];
    //创建sparkMD5对象
    let spark = new SparkMD5.ArrayBuffer();
    //创建文件读取对象
    let fileReader = new FileReader();
    let fileHash = null;

    //FilerReader onload事件，下面执行到fileReader.readAsArrayBuffer会触发onload
    fileReader.onload = (e) => {
      //当前读取的分块结果 ArrayBuffer
      const curChunk = e.target.result;
      //将当前分块追加到spark对象中
      spark.append(curChunk);
      currentChunkCount++;
      chunkList.push(curChunk);
      //判断分块是否全部读取成功
      if (currentChunkCount >= targetChunkCount) {
        //全部读取，获取文件hash
        fileHash = spark.end();
        resolve({ chunkList, fileHash });
      } else {
        loadNext();
      }
    };

    //FilerReader onerror事件
    fileReader.onerror = () => {
      reject(null);
    };

    //读取下一个分块
    const loadNext = () => {
      //计算分片的起始位置和终止位置
      const start = chunkSize * currentChunkCount;
      let end = start + chunkSize;
      if (end > targetFile.size) {
        end = targetFile.size;
      }
      //读取文件，触发onLoad
      fileReader.readAsArrayBuffer(blobSlice.call(targetFile, start, end));
    };

    loadNext();
  });
}
```

## 分片上传入口完善

 为了提高上传效率，我们使用并发上传的方式。设置最大并发数，控制同时上传的切片数量。通过逐一上传切片，并监听每个上传请求的完成，从而动态调整并发请求。     并发上传切片的逻辑主要在`processPool`方法中实现。这个方法负责管理并发请求，确保同时只有一定数量的上传请求在处理中。这通过一个简单的请求池`（requestPool）`和控制最大并发数量`（MAX_REQUEST）`来实现。

```js
async function uploadFile(file, baseChunkSize, uploadUrl, vertifyUrl, mergeUrl, progress_cb) {
  const { chunkList, fileHash } = await sliceFile(file, baseChunkSize);
  //所有分片 ArrayBuffer[]
  let allChunkList = chunkList;
  let allChunkCount = allChunkList.length
  //已上传的分片序列 number[]
  let loadedChunkList = [];
  let uploadedChunksCount = loadedChunkList.length
  //上传进度
  let progress = 0;
  //最大并发数量
  let MAX_REQUEST = 6
  //发送请求,获取文件上传状态
  if (vertifyUrl) {
    const { data } = await requestInstance.post(vertifyUrl, {
      fileHash,
      totalCount: allChunkList.length,
      extname: '.' + file.name.split('.').pop(),
    });
    const { loadedFileList, message } = data;
    if (message) console.info(message);

    //部分上传成功，更新loadedChunkList
    loadedChunkList = loadedFileList;
    uploadedChunksCount = loadedChunkList.length
  }

  //同步上传进度，断点续传情况下
  progress = uploadedChunksCount / allChunkCount) * 100;
  
  //上传
    processPool(fileHash) {
      while (uploadedChunksCount < allChunkCount && MAX_REQUEST > 0) {
        const { chunk, index } = allChunkList.shift(); // 取出一个待上传的切片
        if (!loadedChunkList.includes(index)) {
            uploadChunk(chunk, fileHash, index, uploadUrl) // 上传切片
           .then(() => {
            uploadedChunksCount++; // 更新已上传切片数量
            uploadProgress = ((uploadedChunksCount / allChunkCount) * 100).toFixed(2); // 更新上传进度
            if (uploadedChunksCount < allChunkCount) {
               processPool(fileHash); // 继续处理请求池
            } else if (uploadedChunksCount === allChunkCount) {
           // 所有切片都已上传,发送请求，通知后端进行合并 //后缀名可通过其他方式获取，这里以.mp4为例
          requestInstance.post(mergeUrl, { fileHash, extname: '.mp4' });
            }
          })
          .finally(() => {
            MAX_REQUEST++; // 释放一个请求槽
          });
           MAX_REQUEST--; // 占用一个请求槽
        }
      }
    }
    processPool(fileHash); // 开始处理请求池
}
```

在上传时我们调用了`uploadChunk()`方法，**由于我们的请求不仅包含文件，还包含分片索引以及`hash`值，因此我们的请求体应该是`formData`，还有一点需要就是此时我们传入的`chunk`的类型是`ArrayBuffer`,而`formData`中文件的类型应该是`Blob`。** 具体代码如下：

```js
async function uploadChunk(chunk, index, fileHash, uploadUrl) {
  let formData = new FormData();
  //注意这里chunk在之前切片之后未ArrayBuffer，而formData接收的数据类型为 blob|string
  formData.append('chunk', new Blob([chunk]));
  formData.append('index', index);
  formData.append('fileHash', fileHash);
  return requestInstance.post(uploadUrl, formData);
}
```