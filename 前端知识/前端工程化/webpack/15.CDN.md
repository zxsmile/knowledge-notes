# 一、`CDN`概念

`CDN`全称叫做“`Content Delivery Network`”，中文叫**内容分发网络**，和 `DNS` 结合，让用户访问延迟最小的节点，当用户请求资源时，就近返回节点上缓存的资源，而不需要每个用户的请求都到源站获取，避免网络拥塞、缓解源站压力，保证用户访问资源的速度和体验。

`CDN` 系统能够实时地根据**网络流量和各节点的连接、负载状况以及到用户的距离和响应时间**等综合信息将用户的请求**重新导向**离用户**最近**的服务节点上（如下图所示）。其目的是使用户可就近取得所需内容，解决 Internet 网络拥挤的状况，提高用户访问网站的响应速度。

实际上`CDN`这个概念是在1996年由美国麻省理工学院的一个研究小组为**改善互联网的服务质量**而提出的。那么它到底是怎么改善互联网服务质量的呢？

## 从“直播”理解一些和 `CDN`有关的名词

从上面的描述中我们得知了 `CDN`的作用以及大概原理，但是其中的细节并没有展开来说。其实 `CDN`的一些细节通常会和一些名词联系上，例如**负载均衡**、**源站**之类的。同样的，我们以一个身边的例子——**“直播”**——来讲解这些和`CDN`有关的名词。

我们知道，视频其实是由一帧一帧的图片组成的，所以直播的时候我们收到的视频画面的流程可以近似理解为下面这样👇

![webpack234](..\images\webpack234.png)

然而事实是这样的吗？当然不是！一个主播怎么可能只有一个观众，所以应该是下面这样👇

![webpack235](..\images\webpack235.png)

上图的方式是主播把相同的数据同时传给多个不同的观众，这当然是非常愚蠢的方式，**同样的数据**被传了多次，主播端的瓶颈非常明显，比如有1000个观众同时观看的时候，主播端根本无法承担这么多的数据传输。

所以很容易想到的一个方式就是在主播和用户之间增加一个性能**非常强悍**的服务器充当**中间人**的角色，从服务器把数据发给不同用户，也就是下面这样👇

![webpack236](..\images\webpack236.png)

这里的服务器主要有两个作用：1. 接收来自主播的数据（推流）；2. 将收到的数据分发给用户（分发）。

> 当然，如果这里的服务器性能过于强悍，那么它除了可以执行推流和分发的作用外，还可以实现美颜、特效、鉴黄等功能。这时，这台服务器就又多了一个身份——**流媒体处理中心**。

可是一台服务器的性能也是有上限的，假设一台服务器最多可以支持1000个用户同时观看的话，如果用户数远远大于1000的话又该怎么办呢？相信读到这里的小伙伴一定都知道可以怎么做了，没错，那就是再添加一层服务器（集群），如下图所示👇

![webpack237](..\images\webpack237.png)

在上图中，服务器0负责接收主播的视频数据，然后传递给服务器1、2、3……，然后再由这些服务器分发给用户。考虑到用户之后有可能还会访问这些数据，所以他们就干脆把数据在服务器1、2、3……上都存储了一份。

## 相关名词

接下来我们从上面的描述中来理解一些概念。

#### 负载均衡

当观众人数不太多的时候，例如总共只有1000人，那么是选择让某一台服务器服务这1000人，还是3台服务器分担1000人，还是2台？机器也会有新旧之分，老机器只能抗800数量，那要怎么来分配呢？等等问题。这里就需要有一个策略来做资源的分配。这个策略叫做：负载均衡。负载均衡通常可以利用**重定向、反向代理等**方式实现，常用的负载均衡算法有**轮询法、随机法、最小连接数法等**（篇幅问题，这里不再阐述）。

#### `CDN`缓存

考虑到用户之后有可能还会访问这些数据，所以他们就干脆把数据在服务器1、2、3……上都存储了一份（最简单的例子就是多个用户可能会在不同的时间段访问同一张图片）。这个概念叫做：`CDN`缓存。

回源、源站、边缘节点

当分配到服务器1的第一个观众进入时，服务器1是没有存储数据的，它会向服务器-0获取数据，这个过程叫做：回源；相应的，服务器-0被称为：源站；服务器1、2、3……这些负责内容分发的被称为边缘节点。

#### 缓存命中/缓存命中率

观众请求的数据如果由`CDN`缓存提供，叫做缓存命中，所有用户请求的缓存命中比例叫做缓存命中率，它是衡量`CDN`质量的关键指标。

#### 就近原则

一名新进入的观众会被分配到哪一台服务器上呢？理论上，这台服务器距离用户的网络链路越短、不跨网，数据的传输的稳定性就越好，这个叫做：就近原则。

## 使用 `CDN`的好处

说了这么多，如果只是为了加速网站的访问速度，完全可以选择其他方式，为什么一定要用 `CDN` 呢？或者说，除了可以加速，`CDN`还有什么好处？

1. 有利于搜索排名。谷歌等搜索引擎已经把网站访问速度作为一个结果排名的重要指标了。
2. 网站不容易宕机。其实这就和把鸡蛋放在很多篮子里是一个道理，多个服务器分流之后，源站的压力就会小很多。
3. 减少托管成本。大多数服务器的带宽都是有限制的，分流之后不同的文件被存放在不同的服务器上，可以减少带宽产生的费用。

# 二、`CDN`原理分析

## 原理理解

过去几十年，计算机网络把几乎全世界的计算机都连接了起来，我们只要把静态资源和动态的代码部署到服务器上，然后启动服务监听某个端口，这样世界各地的计算机就都能访问该网站。

但是这样有个问题，资源最终还是通过物理层网络线路和设备传输的，每经过一段线路、一个网络设备都有一些耗时，所以客户端和服务器相距越远，网站打开速度就越慢。

这就像你从海南买了一件东西，如果你人在广州的话，那可能很快就收到了，因为传输距离近，但如果你在北京的话，那可能就要多等几天了，因为中间经过的线路、节点都比较多。

但这样肯定不行的，用户体验会很差。怎么解决这个问题呢？

离得越远网站打开速度就越慢，很容易想到，如果部署到很多个地方，当用户访问网络的时候，访问最近的那个不就行了？

这就像快递都有一些中转的仓库，可以存放一些货物，如果你人在北京，要买一个海南的东西，恰好北京的仓库里有，那岂不是很快就可以收到了。

![webpack225](..\images\webpack225.png)

思路是没问题，但是怎么实现呢？

用户是通过域名访问网站的，那能不能通过 `DNS `服务器来实现这个功能呢？

客户端访问某个域名的时候，会先查找本地 `hosts` 文件，如果能查到` ip` 就直接访问。

否则会向本地 `DNS `服务器发请求，这个是联通、移动等运营商提供的每个城市都有的 `DNS `服务器。由它去域名服务器发送解析域名的请求，然后把结果返给客户端。

域名是分层解析的，有根域名服务器、顶级域名服务器、权威域名服务器三层，比如 `image.baidu.com` 会先向根域名服务器发请求查询 `com` 的顶级域名服务器的` ip`，然后再向 `com` 顶级域名服务器查询 `image.baidu.com` 的权威域名服务器的` ip`。查询到权威域名服务器之后，任意层级的域名都会在这里解析（所以叫权威域名服务器）。

看到这个权威域名服务器的时候，不知道大家是否就想到怎么实现 `CDN`网络了。

## 实现 `CDN`网络

**能不能在权威域名服务器这一层根据客户端的` ip` 做一下负载均衡呢？**比如北京来的 `DNS `请求就返回北京机房的服务器的` ip`，上海来的 `DNS `请求就返回上海机房的服务器的` ip`。

确实可以这样实现内容的就近分发，这样的负载均衡网络就叫做 `CDN`（`Content Delivery Network`）

但是实现这样一个 `CDN`网络需要在全国建立多个机房，成本太高了，所以只有像百度、阿里、腾讯这类大公司才会自建 `CDN`，一般情况下我们都会买第三方的 `CDN`服务来用。

这些公司建好了 `CDN`网络，实际上自己也是用不完的，也会对外提供 `CDN`加速服务。

第三方的 `CDN`服务自然也要提供一个 `DNS `服务器，也就是实现根据` ip` 返回不同城市的服务器的` ip` 的那个。

比如这是百度云 `CDN`的原理图：

![webpack226](..\images\webpack226.png)

用户向本地 `DNS` 服务器发请求之后，经历根域名、顶级域名的 `DNS`  解析，最终会转给权威 `DNS`  服务器。这时候只要权威 `DNS` 服务器再转给 `baidu` 的 `DNS` 服务器就可以了，这样就能接入 `CDN` 服务。

**`baidu` 的 `DNS` 服务器实现了负载均衡，会根据请求 `ip`  所在的城市，返回不同城市的服务器的 `ip`  。也就实现了就近分发的网络加速功能。**

进入到`CDN`的全局负载均衡系统进行智能调度：

- 看用户的 IP 地址，查表得知地理位置，找相对最近的边缘节点
- 看用户所在的运营商网络，找相同网络的边缘节点
- 检查边缘节点的负载情况，找负载较轻的节点
- 其他，比如节点的“健康状况”、服务能力、带宽、响应时间等

结合上面的因素，得到最合适的边缘节点，然后把这个节点返回给用户，用户就能够就近访问`CDN`的缓存代理

#### 那这个从权威 `DNS`  到 `baidu` 的 `DNS`  的转发是怎么实现的呢？

`DNS` 的记录有很多种类型，比如：

`A` 代表 **`address`**，记录域名对应的 `ip`  。

`CNAME` 代表域名还有一个别名，可以向那个域名来查 `ip`  。

`MX` 代表件名后缀对应的域名或者 `ip`  

看到这个 `CNAME` 类型，大家应该就想到怎么实现转发了。

只要自己在 `DNS` 服务器上配一条 `CNAME` 的记录，指向 `CDN` 服务器的域名就可以了。

比如你用某云的 `CDN`  的时候，第一步也是要配置下自己的 `DNS` 服务器的 `CNAME`  指向它：

![webpack227](..\images\webpack227.png)

这样，当你访问某个域名的时候，解析域名的权威服务器会返回 `CDN` 服务的 `DNS` 服务器的域名，然后再向这台 `CDN`  的 `DNS`  服务器发送解析域名的请求，这时候它就可以根据 `ip` 所在城市来返回一个就近城市的服务器给你。

当然，也可以再做一层 `CNAME`  转发，比如 `CDN` 的 `DNS` 服务器把域名解析转给城市的 `DNS` 服务器，然后城市的 `DNS` 服务器再根据不同机器的负载情况来返回一台离得近而且负载比较小的服务器的 `ip` 给客户端。

这样客户端就能从最近的服务器下载静态资源，从而更快地打开网站。

如果访问的资源没有的时候，会向源站服务器发请求来拿对应的资源并且缓存下来，之后再此访问就不用访问源站了

# 三、`CDN`的组成

##  部署架构

`CDN` 系统设计的首要目标是尽量**减少用户的访问响应时间**，为达到这一目标，`CDN`系统应该尽量将用户所需要的内容**存放在距离用户最近的位置**。也就是说，负责为用户提供内容服务的 `Cache` 设备应部署在物理上的网络边缘位置，我们称这一层为`CDN`边缘层。`CDN`系统中负责全局性管理和控制的设备组成中心层，中心层同时保存着最多的内容副本，当边缘层设备未命中时，会向中心层请求，如果在中心层仍未命中，则需要中心层向源站回源。

不同`CDN`系统设计之间存在差异，中心层可能具备用户服务能力，也可能不直接提供服务，只向下级节点提供内容。如果`CDN`网络规模较大，边缘层设备直接向中心层请求内容或服务会造成中心层设备压力过大，就要考虑在边缘层和中心层之间部署一个区域层，负责一个区域的管理和控制，也保存部分内容副本供边缘层访问。

如图是一个典型的`CDN`系统三级部署示意图:

![webpack233](..\images\webpack233.png)





内容分发网络（`CDN`）是由多个节点组成的。一般来讲，`CDN`网络主要由中心节点、边缘节点两部分构成。

![webpack228](..\images\webpack228.png)

## 中心节点

中心节点包括`CDN`网管中心和全局负载均衡`DNS`重定向解析系统，负责整个`CDN`网络的分发及管理。

## 边缘节点

`CDN`边缘节点主要指异地分发节点，由负载均衡设备、高速缓存服务器两部分组成。

负载均衡设备负责每个节点中各个`Cache`的负载均衡，保证节点的工作效率；同时还负责收集节点与周围环境的信息，保持与全局负载均衡`DNS`的通信，实现整个系统的负载均衡。

高速缓存服务器（`Cache`）负责存储客户网站的大量信息，就像一个靠近用户的网站服务器一样响应本地用户的访问请求。通过全局负载均衡`DNS`的控制，用户的请求被透明地指向离他最近的节点，节点中`Cache`服务器就像网站的原始服务器一样，响应终端用户的请求。因其距离用户更近，故其响应时间才更快。

**中心节点就像仓配网络中负责货物调配的总仓，而边缘节点就是负责存储货物的各个城市的本地仓库。**

目前，主要由很多提供`CDN`服务的云厂商在各地部署了很多个`CDN`节点，拿阿里云举例，我们可以在阿里云的官网上了解到：阿里云在全球拥有2500+节点。中国大陆拥有2000+节点，覆盖34个省级区域，大量节点位于省会等一线城市。海外和港澳台拥有500+节点，覆盖70多个国家和地区。

![webpack229](..\images\webpack229.png)

图：阿里云在中国大陆的`CDN`节点的分布情况

有了如上图的阿里云在中国大陆的`CDN`节点的分布之后（这是不是也和我们前面看到的那张菜鸟网络的全国仓网很像），一个在杭州的电信网络用户，访问某个部署在阿里云上面的网站时，获取到的一些资源，如页面上的某个图片、某段影片或者某些文字，可能就是该网站预先分发到浙江的某个移动`CDN`存储节点提供的，这样就可以大大的减少网站的响应时间。

# 四、访问`CDN`流程详解

**基础架构：**最简单的`CDN`网络由一个`DNS`服务器和几台缓存服务器]组成：

1. 当用户点击网站页面上的内容`URL`，经过本地`DNS`系统解析，`DNS`系统会最终将域名的解析权交给**`CNAME`指向的`CDN`专用`DNS`服务器。**

2. `CDN`的`DNS`服务器将**`CDN`的全局负载均衡设备**`IP`地址返回用户。

3. 用户向`CDN`的全局负载均衡设备发起内容`URL`访问请求。

4. `CDN`全局负载均衡设备根据用户`IP`地址，以及用户请求的内容`URL`，选择一台用户所属区域的**区域负载均衡设备**，告诉用户向这台设备发起请求。

5. **区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务**，选择的依据包括：

   根据用户`IP`地址，判断哪一台服务器距用户最近；

   根据用户所请求的`URL`中携带的内容名称，判断哪一台服务器上有用户所需内容；查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。

   基于以上这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的`IP`地址。

6. 全局负载均衡设备把服务器的`IP`地址返回给用户。

7. 用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

![webpack232](..\images\webpack232.png)

## `CDN`关键技术

对比可以看出，`CDN`将用户的请求路由到`CDN`节点上；将源站点的数据拉取到`CDN`节点上，并做缓存等，实现了对用户站点的加速，那么`CDN`如何实现这些功能点，`CDN`主要利用了四大关键技术（内容路由技术、内容分发技术、内容存储技术、内容管理技术）来实现。

#### 1、内容路由

内容路由功能是由`CDN`负载均衡系统来实现的。它的作用是将用户的请求导向整个`CDN`网络中的最佳节点，最佳节点可以是最近节点，延时最低节点等等，负载均衡的准确性和效率直接决定了整个`CDN`的效率和性能。
通常负载均衡可以分为两个层次：全局负载均衡（`GSLB`）和本地负载均衡（`SLB`）。全局负载均衡（`GSLB`）主要的目的是在整个网络范围内将用户的请求定向到最近的节点（或者区域）。本地负载均衡（`SLB`）一般局限于一定的区域范围内，其目标是在特定的区域范围内寻找一台最适合的节点提供服务，因此，`CDN`节点的健康性、负载情况、支持的媒体格式等运行状态是本地负载均衡进行决策的主要依据。

#### 2、内容分发

内容分发是指将内容从源站发送到`CDN`边缘的`Cache`的过程。目前主要有两种主流的内容分发技术：`PUSH`（分发）、`PULL`（回源）

`PUSH`（分发）是一种 **主动** 分发的技术。通常，`PUSH`由内容管理系统发起，将内容从源或者中心媒体资源库分发到各边缘的`Cache`节点。分发的协议可以采用 `HTTP/FTP`等。通过`PUSH`分发的内容一般是比较热点的内容，这些内容通过`PUSH`方式预分发（`Preload`）到边缘`Cache`，可以实现有针对的内容提供。对于`PUSH`分发需要考虑的主要问题是分发策略，即在什么时候分发什么内容。一般来说，内容分发可以由`CP`（内容提供商）或者`CDN`内容管理员人工确定，也可以通过智能的方式决定，即所谓的智能分发。它根据用户访问的统计信息，以及预定义的内容分发的规则，确定内容分发的过程。

`PULL`（回源）是一种 **被动** 的分发技术，`PULL`分发通常由用户请求驱动。当用户请求的内容在本地的边缘`Cache`上不存在（未命中）时，`Cache`启动`PULL`方法从内容源或者其他`CDN`节点实时获取内容。在`PULL`方式下，内容的分发是按需的。

#### 3、内容存储

对于`CDN`系统而言，需要考虑两个方面的内容存储问题。一个是内容源的存储，一个是内容在`Cache`节点中的存储。

对于内容源的存储，由于内容的规模比较大（通常可以达到几个甚至几十个`TB`），而且内容的吞吐量较大，因此，通常采用海量存储架构。

对于在`Cache`节点中的存储，是`Cache`设计的一个关键问题。需要考虑的因素包括功能和性能两个方面：在功能上包括对各种内容格式的支持、对部分缓存的支持，在性能上包括支持的容量、多文件吞吐率、可靠性、稳定性。

#### 4、内容管理

内容管理在广义上涵盖了从内容的发布、注入、分发、调整、传递等一系列过程。在这里，内容管理重点强调内容进入`Cache`点后的内容管理，我们称为本地内容管理。

本地内容管理主要针对一个`CDN`节点（由多个`CDN Cache`设备和一个`SLB`设备构成）进行。本地内容管理的主要目标是提高内容服务的效率，提高本地节点的存储利用率。通过本地内容管理，可以在`CDN`节点实现基于内容感知的调度，通过内容感知的调度，可以避免将用户重定向到没有该内容的`Cache`设备上，从而提高负载均衡的效率。通过本地内容管理还可以有效地实现在`CDN`节点内容的存储共享，提高存储空间的利用率。

## `CDN`的特点

- 本地`Cache`加速 提高了企业站点（尤其含有大量图片和静态页面站点）的访问速度，并大大提高以上性质站点的稳定性 　　
- 镜像服务 消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量。
- 远程加速 远程访问用户根据`DNS`负载均衡技术智能自动选择`Cache`服务器，选择最快的`Cache`服务器，加快远程访问的速度 　　
- 带宽优化 自动生成服务器的远程`Mirror`（镜像）`Cache`服务器，远程用户访问时从`Cache`服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点`WEB`服务器负载等功能。 　　
- 集群抗攻击 广泛分布的`CDN`节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种`D.D.o.S`攻击对网站的影响，同时保证较好的服务质量 。

# 五、`CDN`的组成部分

典型的`CDN`由三个部分组成：分发服务系统、负载均衡系统、运营管理系统

- **分发服务系统**：最基本的工作单元是`Cache`设备，`Cache`负责直接响应最终用户的访问请求，把缓存在本地的内容快速提供给用户。同时`Cache`还负责与源站点进行内容同步，把最新的内容从源站获取下来并保存在本地。`Cache`设备的数量、规模、总服务能力是衡量一个`CDN`系统服务能力的最基本指标。
- **负载均衡系统**：主要功能是负责对所有发起请求的用户进行访问调度，确定提供给用户的最终实际访问地址。两级调度体系分为全局负载均衡（`GSLB`）和本地负载均衡（`SLB`）。全局负载均衡主要根据用户的就近原则，通过对每个服务节点进行最优判断，确定向用户提供服务的`Cache`的物理地址。本地负载均衡主要负责节点内部的设备负载均衡。
- **运营管理系统**：运营管理系统分为运营管理和网络管理子系统，负责处理业务层面与外界系统交互所必须的手机、整理与交互。

# 六、`CDN`缓存

## 浏览器缓存刷新

1.（重新加载）在地址栏中输入网址后按回车或点击转到按钮

浏览器以最少的请求来获取网页的数据，浏览器会对所有没有过期的内容直接使用本地缓存，从而减少了对浏览器的请求。所以，`Expires`，`max-age`标记只对这种方式有效。

2.(普通刷新)按`F5`或浏览器刷新按钮

浏览器会在请求中附加必要的缓存协商，但不允许浏览器直接使用本地缓存，它能够让 `Last-Modified`、`ETag`发挥效果，但是对`Expires`无效。

3.（强制刷新）按`Ctrl+F5`或按`Ctrl`并点击刷新按钮

这种方式就是强制刷新，总会发起一个全新的请求，不使用任何缓存。

浏览器本地缓存失效后，浏览器会向`CDN`边缘节点发起请求。类似浏览器缓存，`CDN`边缘节点也存在着一套缓存机制。

## `CDN`缓存的缺点

`CDN`的缓存不仅减少了用户的访问延时，也减少的源站的负载。但其缺点也很明显：当网站更新时，如果 `CDN`节点上数据没有及时更新，即便用户再浏览器使用 `Ctrl+F5` 的方式使浏览器端的缓存失效，也会因为 `CDN` 边缘节点没有同步最新数据而导致用户访问异常。

## `CDN`的缓存机制

`CDN`边缘节点缓存策略因服务商不同而不同，但一般都会遵循 `http`标准协议，通过 `http`响应头 中的`Cache-control: max-age` 的字段来设置 `CDN`边缘节点数据缓存时间。

当客户端向 `CDN`节点请求数据时，`CDN`节点会判断缓存数据是否过期，若缓存数据并没有过期，则直接将缓存数据返回给客户端；否则，`CDN`节点就会向源站发出回源请求，从源站拉取最新数据，更新本地缓存，并将最新数据返回给客户端。

`CDN`服务商一般会提供基于文件后缀、目录多个维度来指定`CDN`缓存时间，为用户提供更精细化的缓存管理。

`CDN`缓存时间会对“回源率”产生直接的影响。若`CDN`缓存时间较短，`CDN`边缘节点上的数据会经常失效，导致频繁回源，增加了源站的负载，同时也增大的访问延时；若`CDN`存时间太长，会带来数据更新时间慢的问题。开发者需要增对特定的业务，来做特定的数据缓存时间管理。

所以，如果我们修改了内容，最好加个版本号，来容 `CDN`重新获取资源，从而减少不必要的麻烦，比如 :

`app.js?v=20171114` 或者 `style.css?v=20171114`

## `CDN`缓存刷新

`CDN`边缘节点对开发者是透明的，相比于浏览器 `Ctrl+F5` 的强制刷新来使浏览器本地缓存失效，开发者可以通过 `CDN`服务商提供的 刷新缓存 接口来达到清理 `CDN`边缘节点缓存的目的。这样开发者在更新数据后，可以使用刷新缓存功能来强制 `CDN`节点上的数据缓存过期，保证客户端在访问时，拉取到最新的数据。

## `CDN`命中率、回源率常见问题

#### `CDN` 命中率如果较低的原因是什么？

1. 源站动态资源较多，多为不可缓存的内容，也会导致频繁回源拉取。
2. 资源访问量较低，文件热度不够，`CDN`收到请求较少无法有效命中缓存。
3. 缓存配置不合理，缓存时间过短，`CDN`节点频繁回源。
4. 访问资源的 `URL` 带参数，并且参数不断变化，当用不同的 `URL`  去访问 `CDN` 的时候，`CDN`会认为这是一个新请求（即便这两个不同的 `URL`  其实是访问到了同一个文件，并且该文件已经缓存在节点上），会回源去拉取所请求的内容。

#### `CDN`什么情况下会回源拉取资源？

1. 用户访问时，如节点上无缓存，则会回源拉取资源
2. `CDN`节点上的文件超时过期，会回源拉取资源
3. 若为不缓存文件，用户访问时，会直接回源
4. 未忽略 `URL` 参数域名，使用该形式域名带参数访问资源，会直接回源

# 七、相关问答

#### 1、`CDN`加速是对网站所在服务器加速，还是对其域名加速？

`CDN`是只对网站的某一个具体的域名加速。如果同一个网站有多个域名，则访客访问加入`CDN`的域名获得加速效果，访问未加入`CDN`的域名，或者直接访问`IP`地址，则无法获得`CDN`效果。

#### 2、`CDN`和镜像站点比较有何优势？

`CDN`对网站的访客完全透明，不需要访客手动选择要访问的镜像站点，保证了网站对访客的友好性。　　
`CDN`对每个节点都有可用性检查，不合格的节点会第一时间剔出，从而保证了极高的可用率，而镜像站点无法实现这一点。　　
`CDN`部署简单，对原站基本不做任何改动即可生效。

#### 3、`CDN`和双线机房相比有何优势？

常见的双线机房只能解决网通和电信互相访问慢的问题，其它`ISP`（譬如教育网，移动网，铁通）互通的问题还是没得到解决。　　
而`CDN`是访问者就近取数据，而`CDN`的节点遍布各`ISP`，从而保证了网站到任意`ISP`的访问速度。另外`CDN`因为其流量分流到各节点的原理，天然获得抵抗网络攻击的能力。

#### 4、`CDN`使用后，原来的网站是否需要做修改，做什么修改？

一般而言，网站无需任何修改即可使用`CDN`获得加速效果。只是对需要判断访客`IP`程序，才需要做少量修改。

#### 5、为什么我的网站更新后，通过`CDN`后看到网页还是旧网页，如何解决？　　

由于`CDN`采用各节点缓存的机制，网站的静态网页和图片修改后，如果`CDN`缓存没有做相应更新，则看到的还是旧的网页。
为了解决这个问题，`CDN`管理面板中提供了URL推送服务，来通知`CDN`各节点刷新自己的缓存。　　
在`URL`推送地址栏中，输入具体的网址或者图片地址，则各节点中的缓存内容即被统一删除，并且当即生效。　　
如果需要推送的网址和图片太多，可以选择目录推送，输入 http://www.kkk.com/news即可以对网站下`news`目录下所有网页和图片进行了刷新。

#### 6、能不能让`CDN`不缓存某些即时性要求很高的网页和图片？

只需要使用动态页面，`asp，php，jsp`等动态技术做成的页面不被`CDN`缓存，无需每次都要刷新。或者采用一个网站两个域名，一个启用`CDN`，另外一个域名不用`CDN`，对即时性要求高的页面和图片放在不用`CDN`的域名下。

#### 7、网站新增了不少网页和图片，这些需要使用`URL`推送吗？　　

后来增加的网页和图片，不需要使用`URL`推送，因为它们本来就不存在缓存中。

#### 8、网站用`CDN`后，有些地区反映无法访问了，怎么办？

`CDN`启用后，访客不能访问网站有很多种可能，可能是`CDN`的问题，也可能是源站点出现故障或者源站点被关闭，还可能是访客自己所在的网络出现问题，甚至我们实际故障排除中，还出现过客户自己计算机中毒，导致无法访问网站。　　

#### 9、如何找到最近的代理服务器？

`CDN`是如何将寻找最近的代理服务器？两个关键因素如下：

1. 网络距离又包含以下两个主要因素：
   - 网络路径长度：用户与代理服务器之间的物理距离决定了网络路径的长度。较短的路径通常会导致较低的延迟。
   - 容量（带宽）限制：网络路径上的容量或带宽也影响接近性。最佳接近性涉及选择路径最短且可用带宽最高的服务器。这确保了更快的内容传递给用户。
2. 请求负载：代理服务器在任何给定时间的负载，即请求负载，是另一个重要考虑因素。如果一组代理服务器负载较高，请求路由系统应将请求重定向到负载较低的服务器。这有助于平衡代理服务器的负载并减少用户的响应延迟。

#### 10、如何将请求路由到最近的代理服务器?

1. `DNS`重定向：基于 `DNS`的重定向涉及将域名映射到靠近客户端的代理服务器的`IP`地址。当客户端发送`DNS`查询以解析域名时，`DNS`服务器响应最近代理服务器的`IP`地址，指导客户端到该服务器获取内容。
2. `Anycast：Anycast`路由是一种网络寻址和路由技术，将数据包定向到共享相同`IP`地址的一组服务器中最近或性能最佳的节点。使用`Anycast`，多个代理服务器广播相同的`IP`地址，路由器根据网络拓扑自动将流量路由到最近的服务器，最小化延迟并提高可靠性。
3. 客户端多路复用：客户端多路复用涉及在客户端和不同代理服务器之间保持多个并发连接。这允许客户端同时连接多个服务器，并选择延迟最低的服务器进行内容检索。
4. `HTTP`重定向：基于`HTTP`的重定向涉及代理服务器使用`HTTP`状态码（如301（永久移动）或302（找到））将客户端重定向到更近的服务器。当客户端向代理服务器发送请求时，服务器评估客户端的位置并将请求重定向到最近的服务器进行数据检索。

#### 11、说说为啥`CDN`可以加快客户端获取资源的速度

![webpack238](..\images\webpack238.png)

`cdn`网络中有多个边缘节点服务器；我们将资源上传到源服务器（通常是业务部署的业务服务器）之后，经过`cdn`网络的中心调度，可以将源服务器里的资源部署到各个边缘节点服务器；客户端就可以从最近的一个边缘节点服务器获取需要的资源，实际上就是从物理上缩短资源传输距离，加快了资源的获取速度。

#### 12、照这么整，从`CDN`获取资源一定比从业务服务器获取资源快吗？

当然不是，这得分情况，例如当客户端第一次向`cdn`请求某个资源时，流程如下：

![webpack239](..\images\webpack239.png)

1. 客户端会先查询`CDN`域名的距离自己最近的`IP`地址
2. 得到`IP`地址之后，向边缘节点服务器发起资源请求
3. 边缘节点服务器发现自己没有客户端请求的资源，就会问源服务器要
4. 源服务器给边缘节点服务器响应请求的资源，第3和第4步过程称之为**回源**
5. 边缘节点服务器拿到资源之后，会自己缓存一份，并将此资源响应给客户端
6. bingo，客户端拿到最新的资源了

可以看出，如果回源请求资源，将比客户端直接访问源服务器更慢；但是边缘节点有了缓存之后，第二次访问就快了（因为边缘节点服务器距离客户端近），过程如下图

![webpack240](..\images\webpack240.png)

#### 13、既然边缘节点服务器有缓存，怎么保证缓存的资源与源站的资源是相同的（即如果源站资源更新了，客户端怎么无延迟拿到最新的资源）

对于项目打包出来的`js`、`css`等静态资源，在`webpack`打包的时候，可以使用文件hash命名，如`vendor.hash1.js`；资源更新后，打包出来的资源名字就会改变：`vendor.hash2.js`；这样可以保证同名的资源，无论是在源服务器还是边缘节点服务器都是相同的，如下图（假设`cdn`域名为`cdn.example.com`）：

![webpack241](..\images\webpack241.png)

`js`、`css`等静态资源是由`html`引用的（可借助`webpack`将打包出来的最新资源路径注入`html`），因此，只要确保客户端访问的`html`入口文件是最新的，访问到的其余静态资源也是最新的

#### 14、那怎么保证客户端访问的`html`入口文件是最新的，也用`hash`命名吗

入口文件名称一般不会改变，不用文件`hash`命名，如果使用`hash`命名，则每次更新`html`入口文件，都需要在`nginx`上修改重定向入口；假设我们的系统域名为`demo.example.com`，客户端访问此系统的过程如下：

![webpack242](..\images\webpack242.png)

由于客户端访问系统的时候，域名是不变的，`nginx`监听到这个请求就会从`cdn`拿系统的入口文件并返回给客户端；但是`nginx`并不知道入口文件名字，这个名字由运维人员配置的，假如入口文件也用hash命名，那入口文件每次更新都需要去`nginx`上配置最新的名字，才能确保`nginx`去边缘服务器请求最新的入口文件，很麻烦。

所以在边缘节点服务器中，可以将`html`入口文件的缓存时间时间设置得很短，比如5分钟，这样子过几分钟缓存就失效了，边缘节点服务器会回源获取最新的入口文件资源（对于客户端来说近似实时）。而其他的静态资源可以将缓存时间设置长一点，减少回源情况

#### 15、其他静态资源缓存时间设置多长合适？设置永久可以吗

理论上是可行的。因为对于`hash`命名的资源，只要名称相同，内容肯定是相同的，并不会出现源服务器与边缘节点服务器里面同名资源不同内容的情况，设置缓存有效期长一点，就减少一点回源的概率。

但是，边缘节点服务器的容量不是无限大的，即使设置了永久有效，当服务器容量满了的时候，一般会把最旧的资源删掉。

如果项目的迭代周期比较稳定，可以根据迭代周期来设置缓存时效。而且，即使资源过期了，边缘节点服务器也不会立刻回源，而是通过对比一些请求参数决定要不要回源。

##### 16、假如将`html`文件的缓存时效设置为5分钟，会有风险吗

有。。。。。`html`入口文件更新了，大概率意味着是系统的更新，后端服务的接口也有可能更新，比如传入的参数变化了；如果客户端访问到的入口文件是边缘节点服务器中的旧缓存，客户端请求的接口传入的参数还是旧的；如果后端接口没做向下兼容，系统就无法正常使用，甚至导致系统白屏

#### 17、如何避免？

`html`更新的时候，使用`cdn`刷新功能，实际上就是将边缘节点服务器里面的`html`缓存删掉，这样客户端请求时会触发`cdn`回源，就能拿到最新的数据啦。只是。。。。有点危险，搞不好删错东西了，就是导致大量回源，说不定把源服务器整挂了。。。。

#### 18、人到中年，讲求的是稳重，就没别的办法了吗

有，就是`html`不部署到`cdn`里面，部署到一个独立服务器，这个服务器只提供访问`html`的能力，不设置缓存；因为现在`spa`开发出来的`html`文件很小，访问速度还可以接受。

#### 19、考虑这样一个场景，你的产品用户量很大，在下周会搞一个抽奖活动，抽奖页面新开发的，谈谈你怎么利用`cdn`来做优化以确保你这个抽奖活动能够正常使用

由于抽奖页是新发布的，即边缘节点服务器并没有抽奖页资源的缓存，到了抽奖日期可能会导致大量的`cdn`回源；针对这种情况，可以使用`cdn`的预热功能，即在抽奖日期前手动触发边缘节点服务器向源服务器请求资源并缓存起来。

#### 20、预热只能确保用户比较快的访问到抽奖页面（即预热只能预热静态资源），但是抽奖操作、奖品数据不还是得通过`ajax`请求发送到服务器嘛，把服务器搞爆了怎么办

不慌，`cdn`还有数据预取功能，运维人员可以根据用户访问的内容与数据的关联性配置策略，提前从源服务器请求一些公共数据并缓存起来。例如，用户访问抽奖页面，那么肯定会获取奖品列表等数据，这些数据对于每个人都是一样的，`cdn`可以预先从源服务器将这些数据请求回来并缓存，那客户端可以减少请求业务服务端的次数啦。

另外，目前不少`cdn`厂商都在边缘节点服务器提供一些简单的计算能力，并可以将计算结果缓存起来，这样用户的一些简单交互操作就可以直接请求边缘节点服务器啦，进一步降低业务服务端的压力。

# 八、`CDN`的应用场景

## 1.网站与应用加速

`CDN`可用于网站或者应用中大量静态资源的加速分发，如`html`、`css`、`js`、`img`等，可以通过`CDN`缓存在边缘节点上，当用户访问时可就近获取，提高了用户的访问速度以及降低了源站的压力。

## 2.大文件下载分发加速（视频等文件）

`CDN`可以针对各类文件、在线点播视频提供下载、分发加速，比如`mp4`、`flv`视频文件或大小在`20M`以上的文件，`CDN`可以搭配对象存储`OSS`使用，提升回源速度，节约回源带宽成本。

## 3.移动应用加速

`CDN`可以为移动`APP`更新文件分发，为移动`APP`内图片、页面、短视频、`UGC`等内容的优化提供加速分发效果。同时可提供`HTTP DNS`服务，避免`DNS`劫持并获得精确的`DNS`解析结果。

## 4.直播加速

`CDN`可以为直播分发提供流畅的播放下行链路，借助负载均衡系统将主播端采集的音视频数据推送到接近观众的数千个边缘节点，当观众端发起请求，就可以就近获取资源，减少网络抖动，增加直播链路的稳定性。